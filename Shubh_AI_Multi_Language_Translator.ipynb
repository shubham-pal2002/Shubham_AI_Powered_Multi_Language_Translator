{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing required libraries"
      ],
      "metadata": {
        "id": "Kez6hwL9J4f3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LIyKD1lXElho"
      },
      "outputs": [],
      "source": [
        "# Installing all the required packages for model and UI\n",
        "# Install transformers, torch, and gradio\n",
        "!pip install -q transformers torch sentencepiece gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries"
      ],
      "metadata": {
        "id": "T1c96g4IQTP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required libraries\n",
        "# Importing MarianMT translation model and Gradio for the web UI.\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "ktpfgWtZQpSo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining supported languages and language pairs"
      ],
      "metadata": {
        "id": "ckn_AjEaRNSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dictionary of language codes and function to generate model name.\n",
        "# Supported languages\n",
        "languages = {\n",
        "    'English': 'en',\n",
        "    'Hindi': 'hi',\n",
        "    'French': 'fr',\n",
        "    'German': 'de',\n",
        "    'Spanish': 'es'\n",
        "}\n",
        "\n",
        "# Function to get model name for language pair\n",
        "def get_model_name(src_lang, tgt_lang):\n",
        "    return f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'\n"
      ],
      "metadata": {
        "id": "EAkw8ErNRWrn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading translation model"
      ],
      "metadata": {
        "id": "BWeqrbByRz8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads model and tokenizer based on source and target languages.\n",
        "# Function to load model and tokenizer\n",
        "def load_model(src_lang, tgt_lang):\n",
        "    model_name = get_model_name(src_lang, tgt_lang)\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n"
      ],
      "metadata": {
        "id": "6BEStgN9SJgb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining translation function"
      ],
      "metadata": {
        "id": "yQgruCvRSz1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes input text and translates it from source to target language using the loaded model\n",
        "# Translate function\n",
        "def translate(text, from_lang, to_lang):\n",
        "    if from_lang == to_lang:\n",
        "        return text\n",
        "    src = languages[from_lang]\n",
        "    tgt = languages[to_lang]\n",
        "\n",
        "    try:\n",
        "        tokenizer, model = load_model(src, tgt)\n",
        "    except:\n",
        "        return f\"Translation not available for {from_lang} to {to_lang}\"\n",
        "\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
        "    return translated_text\n"
      ],
      "metadata": {
        "id": "jmMfoJ9ZS6wf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Gradio UI"
      ],
      "metadata": {
        "id": "pFlfQLMFTOhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Gradio UI with text input, language dropdowns, and output display\n",
        "# Gradio interface\n",
        "def gradio_interface(text, from_lang, to_lang):\n",
        "    return translate(text, from_lang, to_lang)\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter text here\"),\n",
        "        gr.Dropdown(list(languages.keys()), label=\"From Language\", value=\"English\"),\n",
        "        gr.Dropdown(list(languages.keys()), label=\"To Language\", value=\"Hindi\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Translated Text\"),\n",
        "    title=\"AI-Powered Multi-Language Translator\",\n",
        "    description=\"Translate between English, Hindi, French, German, and Spanish using AI\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "qTFiYh-jTZrU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launhing the interface"
      ],
      "metadata": {
        "id": "9pBTqPY3Tuct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will launch the interactive translation interface with buttons\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "s8x1CbUYT_LD",
        "outputId": "9807c09a-c336-40ea-abac-fe08d52d428e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0931381f0667240413.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0931381f0667240413.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}